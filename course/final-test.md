# Финальный тест

Тест из 10 сценарных вопросов, покрывающих ключевые знания всех 8 модулей курса. Каждый вопрос основан на реальной ситуации из практики разработчика.

---

## Вопрос 1: Реалистичные ожидания (Модуль 1)

Ты на собеседовании в стартап. Техлид говорит: "У нас есть Claude Code, поэтому мы не нанимаем мидл-разработчиков. Один сеньор с агентом заменяет команду из 5 человек." Как правильно оценить эту ситуацию?

**A)** Отлично! Агент действительно может полностью заменить мидл-разработчиков, я буду работать с агентом один на один

**B)** Это red flag: агент — инструмент для усиления продуктивности, а не замена команды. Сеньор будет перегружен ревью AI-кода, архитектурой, блокерами

**C)** Агент может заменить мидлов, если правильно настроить MCP-серверы и оркестрацию

**D)** Нужно попросить Claude Max подписку и тогда это реально

**Правильный ответ:** B

**Объяснение:** Модель зрелости (Модуль 1) показывает: агент на уровне 4-5 действительно многократно увеличивает продуктивность, но не заменяет команду. Сеньор с агентами может делать работу 2-3 разработчиков, но не 5. Остаются задачи, которые агенты не могут: архитектурные решения с бизнес-контекстом, код с неочевидными требованиями, debugging сложных багов в legacy-системах, менторинг джуниоров. Кроме того, огромный объём работы уходит на ревью AI-кода, настройку процессов, разрешение блокеров. Техлид, который считает агента полной заменой людей, скорее всего не имеет реального опыта работы с AI на scale.

---

## Вопрос 2: Выбор инструмента (Модуль 2)

Тебе нужно добавить CRUD endpoints для 15 моделей данных. Endpoints простые, по одинаковому шаблону. У тебя ограниченный бюджет $30/месяц. Какую стратегию выбрать?

**A)** Использовать ChatGPT Plus ($20/мес) — описываешь задачу в чате, копируешь код руками

**B)** Cursor Pro ($20/мес) + агент в Agent Mode пишет все endpoints последовательно, используя Claude Sonnet 4.5

**C)** OpenCode (бесплатно) + DeepSeek R1 API ($5-10/мес) — агент массово генерирует endpoints, проверка через тесты

**D)** Claude Code Max ($100/мес) — максимальное качество кода через Opus 4.6

**Правильный ответ:** C

**Объяснение:** Задача массовая, по шаблону, с формальными критериями приёмки (тесты должны пройти). Это идеальный случай для дешёвой модели в агентном режиме. DeepSeek R1 стоит $0.70/$2.50 за 1M токенов (в 10-30 раз дешевле Claude), достаточно качественен для boilerplate кода, работает в fail-until-done цикле (пишет → тесты → исправляет → повторяет). OpenCode — бесплатный CLI-агент, поддерживает DeepSeek. Итого: ~$5-10 на API вместо $100 на Claude Max. Вариант B (Cursor Pro) дороже и медленнее (Sonnet дороже DeepSeek в 4-5 раз), вариант A (ChatGPT Plus) требует ручного копирования кода — неэффективно для 15 моделей, вариант D — избыточный overkill (Opus для boilerplate — как Ferrari для поездки в магазин).

---

## Вопрос 3: Улучшение промпта (Модуль 3)

Ты даёшь агенту задачу: "Добавь кеширование в API". Агент возвращает код, который добавляет in-memory cache без TTL, без инвалидации, кеширует всё подряд. Что не так с промптом?

**A)** Нужно было указать модель Claude Opus вместо Sonnet

**B)** Промпт слишком короткий — нужно было написать 5 страниц детального ТЗ

**C)** Отсутствует контекст и критерии: какие endpoints кешировать, где хранить кеш (Redis?), TTL для разных данных, как инвалидировать

**D)** Агент просто плохо справился, нужно перезапустить с тем же промптом

**Правильный ответ:** C

**Объяснение:** Модуль 3 учит: качество результата = качество промпта. "Добавь кеширование" — сразу два антипаттерна: нечёткая формулировка и отсутствие контекста. Агент не знает: 1) Какие endpoints нужно кешировать (все? только медленные?), 2) Где хранить кеш (in-memory? Redis? memcached?), 3) TTL (1 минута? 1 час? 24 часа?), 4) Когда инвалидировать (при изменении данных? по расписанию?), 5) Что делать с cache stampede. Правильный промпт: "Добавь Redis-based кеширование для GET /api/products и /api/users. TTL: products — 5 минут, users — 1 минута. Инвалидация: при POST/PUT/DELETE очищать соответствующий кеш. Используй существующий Redis-клиент из config/redis.ts. Покрой тестами." Вариант A (смена модели) не поможет — Opus с плохим промптом даст такой же плохой результат. Вариант B (5 страниц ТЗ) — избыточно, достаточно 10-15 строк с чёткими критериями. Вариант D (перезапустить) — повторение той же ошибки.

---

## Вопрос 4: Постановка задачи агенту (Модуль 4)

Ты ставишь агенту задачу: "Добавь авторизацию в приложение". Агент написал 500 строк кода, добавил JWT, refresh tokens, middleware. Код компилируется, но тестов нет. Что делать?

**A)** Закоммитить — код компилируется, значит работает

**B)** Попросить агента написать тесты, потом сделать полное ревью кода и тестов

**C)** Удалить и переписать руками — слишком много кода, агент не справился

**D)** Попросить агента объяснить каждую строку кода

**Правильный ответ:** B

**Объяснение:** Модуль 4 учит: агент — как джуниор-разработчик. Код без тестов нельзя принимать, даже если компилируется. Компиляция проверяет синтаксис, но не логику. Авторизация — критичный участок кода, ошибки дорого стоят (security breach). Правильный workflow: 1) Попросить агента написать тесты (unit + integration): проверка JWT validation, token expiry, refresh flow, unauthorized access, 2) Запустить тесты — они должны пройти, 3) Сделать ревью кода: нет ли захардкоженных секретов? правильно ли реализован refresh? нет ли SQL-инъекций?, 4) Если найдены проблемы — агент исправляет, 5) Только после прохождения тестов и ревью — коммит. Вариант A — типичная ошибка новичка ("компилируется = работает"). Вариант C — overreaction (500 строк кода — нормально для авторизации с JWT + refresh + middleware). Вариант D — потеря времени (объяснение не заменяет тесты).

---

## Вопрос 5: Надзор и ревью (Модуль 4)

Агент работает в YOLO-режиме (без подтверждений) над фичей "экспорт данных в CSV". Ты видишь в логах: агент прочитал файл `users.db`, выполнил `SELECT * FROM users`, записал в `export.csv`, закоммитил. Какая проблема?

**A)** Нет проблемы — агент выполнил задачу автономно, как и должен

**B)** Агент экспортировал ВСЕ данные пользователей, включая приватные (email, пароли) без фильтрации — security issue

**C)** Агент должен был использовать PostgreSQL вместо SQLite

**D)** YOLO-режим вообще нельзя использовать

**Правильный ответ:** B

**Объяснение:** Модуль 4 (раздел Human-in-the-loop vs Agentic) учит: YOLO-режим допустим для некритичных задач, но требует настройки правил. Проблема: агент экспортировал `SELECT * FROM users` — это включает приватные данные (email, password_hash, возможно телефоны, адреса). Правильный подход: 1) В AGENTS.md/CLAUDE.md зафиксировать правило: "При экспорте пользовательских данных ВСЕГДА фильтруй приватные поля. Экспортируй только: id, username, created_at, last_login", 2) Попросить агента переделать экспорт с фильтрацией, 3) Добавить тест, который проверяет отсутствие приватных полей в экспорте. Вариант A — игнорирование security issue. Вариант C — irrelevant (тип БД не влияет на проблему). Вариант D — категоричное утверждение (YOLO допустим в изолированных окружениях, например в git worktree внутри Docker, как в **Enji Fleet** — учебном проекте Mad Devs).

---

## Вопрос 6: Выбор артефакта (Модуль 5)

У тебя проект с 3 агентами, которые работают параллельно. Агент 1 постоянно забывает использовать Repository pattern для БД и пишет SQL прямо в handlers. Агент 2 и 3 делают правильно. Куда нужно добавить правило?

**A)** В trace-файл агента 1 — чтобы он запомнил

**B)** В Constitution (AGENTS.md) — это обязательное правило для всех агентов

**C)** В feature plan — чтобы агент 1 знал об этом для текущей задачи

**D)** Никуда, просто исправлять вручную каждый раз

**Правильный ответ:** B

**Объяснение:** Модуль 5 (иерархия артефактов) учит: Constitution — это правила, которые не должны нарушаться никогда, всеми агентами, на всех задачах. Если правило обязательное (Repository pattern для БД) — оно идёт в Constitution/AGENTS.md. Trace-файл (вариант A) — это память одного агента об одной задаче, другие агенты его не читают. Feature plan (вариант C) — это спецификация конкретной фичи, правило потеряется после завершения плана. Вариант D — ручные правки каждый раз = техдолг и потеря времени. Правильный подход: добавить в Constitution → раздел "Обязательные паттерны": "Все SQL-запросы ТОЛЬКО через Repository pattern. Запрещено писать SQL прямо в handlers/controllers. Пример: используй UserRepository.findById(), а не db.query('SELECT * FROM users WHERE id=?')". После этого все агенты (включая новых) будут следовать правилу. В **Enji Fleet** (демонстрационный проект) для таких случаев используется reflect-mode: агент-ревьюер читает traces от других агентов, замечает повторяющуюся проблему, предлагает добавить правило в Constitution.

---

## Вопрос 7: Когда нужен MCP (Модуль 6)

Ты работаешь над задачей из Jira: "PROJ-456: Add user profile page". Тебе нужно: 1) Прочитать детальное описание из Jira, 2) Реализовать фичу, 3) Залогировать время работы в Jira. Какой подход оптимален?

**A)** Вручную открыть Jira → скопировать описание → дать агенту → реализовать → вручную залогировать время

**B)** Установить Jira MCP-сервер → агент читает задачу из Jira, реализует, автоматически логирует время

**C)** Попросить агента самому зайти в Jira через браузер

**D)** MCP не нужен, достаточно скопировать URL задачи в промпт

**Правильный ответ:** B

**Объяснение:** Модуль 6 учит: MCP расширяет возможности агента для интеграции с внешними системами. Без MCP (вариант A): вы тратите 5-10 минут на ручные операции (открыть Jira, скопировать описание, acceptance criteria, комментарии, залогировать время после работы). При 10 задачах в неделю = 50-100 минут ручной работы. С Jira MCP (вариант B): агент делает всё автоматически — читает PROJ-456 через API, получает description и acceptance criteria, реализует фичу, создаёт worklog с временем и комментарием "Implemented user profile page using Claude Code", обновляет статус на "Code Review". Экономия времени + нет ошибок (забыл залогировать время, неправильно обновил статус). Вариант C — невозможно (агент не может "зайти в браузер" без специального MCP-сервера типа Puppeteer). Вариант D — URL в промпте не даёт агенту доступ к данным задачи, нужен API-доступ через MCP.

---

## Вопрос 8: Выбор паттерна оркестрации (Модуль 7)

Фича "Система уведомлений" состоит из: 1) API endpoint POST /notifications, 2) Email-сервис через SendGrid, 3) SMS-сервис через Twilio, 4) React UI для настроек уведомлений. Задачи независимые. Как организовать работу 3 агентов?

**A)** Последовательно: агент 1 делает API → агент 2 делает Email → агент 3 делает SMS → агент 1 делает UI

**B)** Паттерн "Генератор + Ревьюер": один агент пишет весь код, другой проверяет

**C)** Паттерн "Декомпозиция": агент 1 — API + Email (backend), агент 2 — SMS (backend), агент 3 — UI (frontend). Все работают параллельно

**D)** Паттерн "Иерархия RPI→R": агент-архитектор планирует → агент-разработчик реализует всё → агент-QA тестирует

**Правильный ответ:** C

**Объяснение:** Модуль 7 (паттерны оркестрации) учит: декомпозиция эффективна, когда задачи независимые и слабо связаны. API endpoint + Email + SMS + UI — естественное разделение на backend и frontend. Агент 1: API endpoint (CRUD для notifications) + интеграция SendGrid. Агент 2: интеграция Twilio для SMS. Агент 3: React компонент для UI настроек. Все три работают параллельно в изолированных git worktrees. Время выполнения: ~40 минут (вместо 2 часов последовательно). Конфликтов минимум (backend и frontend редко трогают одни файлы). Вариант A (последовательно) — медленно и неэффективно. Вариант B (генератор + ревьюер) — подходит для критичного кода, но здесь избыточен (2x дороже, нет особых рисков). Вариант D (иерархия) — избыточен для простой задачи с чёткими границами (иерархия нужна для сложных фич с неочевидными требованиями).

---

## Вопрос 9: Разрешение конфликта (Модуль 7)

Два агента работали параллельно: агент 1 добавил валидацию email в файл `utils/validators.ts`, агент 2 добавил валидацию телефона в тот же файл. Оба создали PR. При слиянии — merge conflict в `validators.ts`. Как решить?

**A)** Отклонить оба PR и переделать задачу с одним агентом

**B)** Выбрать один PR случайно, второй агент пусть переделает с учётом изменений первого

**C)** Агент-арбитр читает оба варианта кода и генерирует объединённую версию с обеими валидациями

**D)** Удалить файл и создать два отдельных файла: `emailValidator.ts` и `phoneValidator.ts`

**Правильный ответ:** C

**Объяснение:** Модуль 7 (раздел "Конфликты при слиянии") учит: когда два агента изменили один файл без смысловых конфликтов (добавили разные функции), агент-арбитр может автоматически разрешить конфликт. Агент-арбитр получает: 1) Исходный файл `validators.ts`, 2) Изменения агента 1 (функция validateEmail), 3) Изменения агента 2 (функция validatePhone), 4) Генерирует финальную версию с обеими функциями. Это автоматизируемый процесс для простых конфликтов (добавление независимых функций, импортов, экспортов). Вариант A — overreaction (задача выполнена, не нужно переделывать). Вариант B — неоптимально (один агент ждёт, теряем время параллельности). Вариант D — излишний рефакторинг (два файла для двух функций = over-engineering, если `validators.ts` изначально задуман как модуль с валидаторами). Исключение: если конфликт смысловой (оба изменили одну функцию по-разному) → тогда нужен ручной ревью (вариант из чеклиста модуля 7).

---

## Вопрос 10: Безопасность (Модуль 8)

Ты настраиваешь Figma MCP-сервер для design-to-code workflow. В конфигурации `~/.claude/mcp.json` нужно указать `FIGMA_ACCESS_TOKEN`. Где правильно хранить токен?

**A)** Прямо в `mcp.json`: `"FIGMA_ACCESS_TOKEN": "figd_abc123..."`

**B)** В переменной окружения: `export FIGMA_ACCESS_TOKEN="figd_abc123..."` в `~/.bashrc`, в mcp.json: `"FIGMA_ACCESS_TOKEN": "${FIGMA_ACCESS_TOKEN}"`

**C)** В `.env` файле в корне проекта, добавить `.env` в `.gitignore`

**D)** В Claude Code нет риска утечки, можно хранить где удобно

**Правильный ответ:** B

**Объяснение:** Модуль 8 (безопасность) учит: API-токены НИКОГДА не должны храниться в plain text в конфигах, которые могут попасть в Git. Правильный подход: 1) Токен в переменной окружения (`export FIGMA_ACCESS_TOKEN="..."` в `~/.bashrc` или `~/.zshrc`), 2) Конфиг ссылается на переменную: `"env": { "FIGMA_ACCESS_TOKEN": "${FIGMA_ACCESS_TOKEN}" }`, 3) Если `mcp.json` случайно попадёт в Git — там будет `${FIGMA_ACCESS_TOKEN}`, а не реальный токен. Вариант A — категорически неправильно (токен в plain text, если `mcp.json` попадёт в публичный репозиторий = instant security breach). Вариант C — частично правильно (`.env` + `.gitignore` работает), но для MCP-конфигов системный подход (environment variables) надёжнее (`.env` легко забыть добавить в `.gitignore`, особенно в новом проекте). Вариант D — опасная ошибка (любой AI-инструмент может логировать данные, отправлять в API для обучения, или просто показывать в trace-файлах). В **Enji Fleet** (учебный пример безопасного управления credentials) используется изолированное хранение credentials: `~/.claude/.credentials.json` с `chmod 0600` (только владелец может читать), токены никогда не логируются, не попадают в Git, не передаются между агентами.

---

## Результаты

**9-10 правильных ответов:** Отлично! Вы усвоили материал курса и готовы применять AI-инструменты на практике на уровне 3-4.

**7-8 правильных ответов:** Хорошо! Основные концепции поняты, рекомендуется повторить слабые места (посмотрите, в каких модулях ошиблись).

**5-6 правильных ответов:** Удовлетворительно. Базовое понимание есть, но нужно глубже изучить модули 4-7 (агенты, SDD, MCP, оркестрация).

**Меньше 5 правильных ответов:** Рекомендуется пересмотреть курс, особенно практические модули. Попробуйте выполнить упражнения из practice.md для каждого модуля.

---

## Следующие шаги

После прохождения теста:

1. **Проверьте свою модель зрелости** — пройдите самодиагностику из Модуля 1 ещё раз, сравните результаты с началом курса
2. **Выберите проект для практики** — примените знания на реальной задаче (фича, рефакторинг, миграция)
3. **Настройте свой стек** — установите инструменты под ваш бюджет и задачи (см. Модуль 2)
4. **Создайте AGENTS.md** для своего проекта — начните управлять контекстом (см. Модуль 5)
5. **Присоединяйтесь к сообществу** — делитесь опытом, учитесь у других (Discord, GitHub, X/Twitter)

Удачи в работе с AI-инструментами!
