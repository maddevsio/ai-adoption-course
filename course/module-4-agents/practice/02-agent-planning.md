# Опиши проблему и получи план от агента

### Цель

Научиться правильно формулировать задачу для агента-планировщика и получать детализированный план реализации с критериями приёмки.

### Новый flow (не "вот тебе готовый промпт")

Вместо копирования готового промпта, вы проходите весь цикл самостоятельно:

1. **Описываете проблему** своими словами (как бы описали коллеге)
2. **Ставите задачу агенту-планировщику**: попросить декомпозировать на подзадачи
3. **Агент выдаёт план** с подзадачами и критериями
4. **Вы ревьюите план** и корректируете
5. **Дополняете требования**: просите добавить тесты, линтер-проверки, etc
6. **Агент реализует** утверждённый план

Это учит думать как Product Owner, который декомпозирует фичи на задачи для команды.

### Пример описания проблемы

**Задача для песочницы task-manager:**

Сейчас в task-manager есть только GET и POST для задач. Нужно добавить возможность обновлять существующую задачу.

**Описание своими словами (как бы сказали коллеге):**

> Нужен эндпоинт для обновления задачи. Должен работать так: клиент отправляет PUT /tasks/{id} с новым title, сервер обновляет задачу в БД и возвращает обновлённую версию. Если задачи с таким ID нет — вернуть 404.

### Промпт для агента-планировщика

Скопируйте этот промпт и запустите в вашем AI-агенте (Claude Code, Cursor, или другой инструмент):

```
Я описываю проблему. Твоя задача — проанализировать её, разбить на мелкие подзадачи, для каждой подзадачи указать критерии приёмки.

Проблема:
Нужен эндпоинт для обновления задачи в task-manager API.
Должен работать так: клиент отправляет PUT /tasks/{id} с новым title в body,
сервер обновляет задачу в БД и возвращает обновлённую версию.
Если задачи с таким ID нет — вернуть 404 Not Found.

Контекст проекта:
- Прочитай AGENTS.md в корне проекта (там указан стек и правила)
- Изучи существующие endpoints (GET /tasks, POST /tasks)
- Посмотри как структурированы тесты для существующих endpoints

Задачи для плана:
1. Опиши текущую архитектуру проекта (какие файлы, как организованы endpoints и БД)
2. Разбей задачу на мелкие подзадачи (например: обновить БД-слой, создать endpoint, написать тесты)
3. Для каждой подзадачи укажи:
   - Что нужно сделать
   - Какие файлы создать или изменить
   - Критерии приёмки (как проверить, что сделано правильно)
   - Какие тесты написать

НЕ реализуй код — только план. Я хочу проверить план перед тем, как ты начнёшь писать код.
```

### Пример ожидаемого плана от агента

Агент должен вернуть план примерно такой структуры:

```markdown
# План реализации: PUT /tasks/{id} endpoint

## Текущая архитектура

- Python + FastAPI проект
- БД: SQLite через SQLAlchemy
- Endpoints в main.py
- Модель Task в models.py с полями: id, title, created_at
- Тесты в tests/test_tasks.py

## Подзадачи

### Подзадача 1: Добавить БД-метод для обновления задачи

**Файл:** db.py (или models.py, в зависимости от структуры)

**Что сделать:**
- Создать функцию update_task(task_id: int, title: str) -> Task | None
- Функция находит задачу по ID, обновляет title, сохраняет в БД
- Возвращает обновлённую задачу или None если не найдена

**Критерии приёмки:**
- Функция имеет type hints
- Использует SQLAlchemy ORM (не raw SQL)
- Обрабатывает случай "задача не найдена"

### Подзадача 2: Создать Pydantic schema для запроса

**Файл:** main.py (или schemas.py)

**Что сделать:**
- Создать класс TaskUpdate(BaseModel) с полем title: str
- Добавить валидацию: title не пустой, длина 1-200 символов

**Критерии приёмки:**
- Schema наследуется от pydantic.BaseModel
- Валидация через Field или validator

### Подзадача 3: Создать PUT /tasks/{id} endpoint

**Файл:** main.py (или routes.py)

**Что сделать:**
- Endpoint принимает task_id (path parameter) и TaskUpdate (body)
- Вызывает update_task() из БД-слоя
- Возвращает 200 + обновлённую задачу или 404 если не найдена

**Критерии приёмки:**
- Endpoint использует async def
- Status codes: 200 для успеха, 404 для not found
- Возвращает Task модель (не dict)

### Подзадача 4: Написать integration тесты

**Файл:** tests/test_tasks.py

**Что сделать:**
Создать тесты для сценариев:
1. Успешное обновление задачи (PUT существующей задачи → 200)
2. Попытка обновить несуществующую задачу → 404
3. Валидация: пустой title → 400 (если есть валидация)
4. Проверка что title действительно обновился в БД

**Критерии приёмки:**
- Все тесты проходят (pytest)
- Coverage для нового endpoint минимум 80%
- Используется тот же паттерн, что и для существующих тестов

### Подзадача 5: Запустить проверки качества

**Что сделать:**
- Запустить pytest (все тесты должны проходить)
- Запустить линтер (ruff check . или npm run lint)
- Убедиться что нет TypeScript/mypy ошибок

**Критерии приёмки:**
- pytest: все тесты зелёные
- Линтер: 0 ошибок
- Код соответствует AGENTS.md conventions
```

### Чеклист: что должно быть в плане

План от агента считается хорошим, если содержит:

- ✅ **Анализ текущей архитектуры** (агент прочитал файлы и понял структуру)
- ✅ **Декомпозиция на подзадачи** (минимум 3-5 подзадач)
- ✅ **Для каждой подзадачи**: что делать, какие файлы, критерии приёмки
- ✅ **Тесты явно указаны** (какие сценарии покрыть)
- ✅ **Проверки качества** (линтер, тесты) включены как отдельная подзадача
- ✅ **Соответствие AGENTS.md** (агент учёл правила из конфигурации)

### Ревью и корректировка плана

После получения плана от агента:

**1. Проверьте, что агент прочитал AGENTS.md:**

Поищите в плане ссылки на технологии, conventions, или правила из AGENTS.md. Например, если в AGENTS.md указано "использовать async/await", план должен содержать "async def" для endpoints.

**2. Проверьте полноту:**

Все ли сценарии покрыты тестами? Агент предусмотрел случаи ошибок (404, валидация)?

**3. Дополните план (пример промпта):**

```
Хороший план. Дополни каждую подзадачу:

1. Для подзадачи с тестами — добавь конкретные assert'ы (что именно проверять)
2. Для подзадачи с endpoint — укажи точную сигнатуру функции
3. Добавь подзадачу: обновить документацию (если есть README с описанием API)

После дополнения — жду финальный план для утверждения.
```

**4. Утвердите план:**

```
План утверждён. Реализуй его. Следуй порядку подзадач. После каждой подзадачи — запускай тесты и проверяй линтер. Если тесты падают — исправь перед переходом к следующей подзадаче.
```

### Задание

1. Откройте ваш AI-агент (Claude Code, Cursor, или другой инструмент)
2. Перейдите в директорию вашего проекта (task-manager)
3. Скопируйте "Промпт для агента-планировщика" (см. выше)
4. Запустите промпт, получите план от агента
5. Проверьте план по чеклисту
6. Дополните план (попросите добавить детали по тестам и линтеру)
7. Утвердите финальный план

**НЕ переходите к реализации на этом шаге.** Остановитесь после получения утверждённого плана.

### Проверка

План готов к реализации, если:

- ✅ Агент прочитал AGENTS.md и учёл правила проекта
- ✅ План содержит 4-6 подзадач
- ✅ Для каждой подзадачи указаны файлы и критерии приёмки
- ✅ Тесты включены в план (минимум 3-4 тестовых сценария)
- ✅ Линтер и quality checks упомянуты
- ✅ Вы понимаете каждую подзадачу и согласны с подходом

### Время выполнения

15 минут
