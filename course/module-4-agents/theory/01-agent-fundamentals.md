# Модуль 4: Работа с AI-агентом

## 1. От консультанта к исполнителю

Главное различие между чатом и агентом не в модели, которая лежит в основе, а в способе взаимодействия и уровне автономности.

**Чат** работает в режиме вопрос-ответ. Вы спрашиваете: "Как реализовать JWT-авторизацию в FastAPI?" — получаете ответ с примером кода и объяснением. Код нужно скопировать, адаптировать к проекту, протестировать самостоятельно. Чат не имеет доступа к файлам проекта, не видит структуру кодовой базы, не может запустить тесты. Это справочная система с интерфейсом на естественном языке.

**Агент** работает в режиме постановки задачи. Вы формулируете задание: "Реализуй JWT-авторизацию для FastAPI с использованием модели User из models.py, создай эндпоинты /login и /refresh, добавь тесты с покрытием 80%+". Агент читает models.py, анализирует существующий код, пишет новые файлы, запускает тесты, итерирует при ошибках, и возвращает работающее решение. Это не консультант — это исполнитель.

Агент работает в цикле **plan → act → observe → adjust**. Он планирует последовательность действий, выполняет их (читает файлы, пишет код, запускает команды), наблюдает результат (вывод тестов, ошибки линтера), корректирует подход при необходимости. Этот цикл продолжается до выполнения критериев приёмки или достижения лимита итераций.

Полезная аналогия: **чат — это Stack Overflow с интерактивным интерфейсом**, агент — это **джуниор-разработчик**, которому вы ставите задачу в ticket tracker. Джуниору нужен контекст, чёткая постановка задачи, критерии приёмки, и ваша ответственность — проверить результат перед мержем в main. Эта ментальная модель помогает калибровать ожидания: не ждите от агента архитектурных прозрений, но рассчитывайте на выполнение рутинных задач с минимальным надзором.

## 2. Постановка задачи: от проблемы к плану

Эффективная работа с агентом начинается с правильной декомпозиции задачи. Большие задачи агенты выполняют хуже, чем последовательность маленьких. Вместо "Добавь систему уведомлений в проект" эффективнее разбить на подзадачи: "Создай модель Notification в БД", "Реализуй сервис для отправки email через SendGrid", "Добавь API endpoint POST /notifications", "Напиши integration-тесты для endpoint". Каждая подзадача — атомарна, проверяема, имеет чёткие границы.

Контекст критичен. Агент не знает структуру проекта, архитектурные решения, code conventions — всё это нужно явно указать. Минимальный контекст для задачи: где лежат файлы, какие зависимости уже установлены, какие паттерны использовать (например, "все API endpoints используют async/await и FastAPI dependency injection"), какие ограничения учитывать ("не изменяй существующую схему БД, только добавляй новые таблицы").

Критерии приёмки превращают размытую задачу в проверяемую. Вместо "код должен работать" используйте конкретные критерии: 1) все тесты проходят (pytest без ошибок), 2) линтер чист (flake8, mypy), 3) покрытие тестами минимум 80% (coverage report), 4) API отвечает согласно OpenAPI-спецификации, 5) код следует PEP 8 и проектным conventions. Агент итерирует до выполнения этих критериев или явно сообщает, что не может выполнить (например, тест падает из-за отсутствующей зависимости, которую нужно обсудить).

**Агент-планировщик** — эффективный паттерн для сложных задач. Вместо того чтобы самостоятельно декомпозировать задачу на подзадачи, вы описываете проблему в общем виде, и агент в режиме планирования предлагает **Plan** (документ с последовательностью шагов, файлами для изменения и порядком выполнения). Вы ревьюите план, корректируете (например, "начни с тестов, потом реализация" или "используй существующий класс EmailService, не создавай новый"), и только после одобрения плана агент переходит к реализации. Это предотвращает ситуацию "агент ушёл не туда на 200 строк кода". Пример: "Проанализируй задачу: добавить rate limiting для API. Предложи план реализации с учётом стека (FastAPI, Redis). Какие файлы создать, какие изменить, в каком порядке." Агент предлагает план, вы комментируете, затем даёте команду "Реализуй этот план".

Интеграция проверки качества в постановку задачи, а не в отдельный этап после, значительно повышает результат. Вместо "Реализуй функцию, потом я скажу запустить тесты" используйте "Реализуй функцию, покрой unit-тестами, убедись что pytest проходит, запусти mypy для проверки типов". Агент сразу настраивается на итеративную разработку с самопроверкой. Это особенно эффективно с **TDD-подходом** (Test-Driven Development — методология разработки, при которой сначала пишутся тесты, потом код для их прохождения): "Сначала напиши тесты для функции parse_url согласно спецификации, затем реализуй функцию так, чтобы все тесты прошли". Агент итерирует: пишет код → тесты падают → исправляет → тесты проходят → задача выполнена.

## 3. Режимы работы: планирование и исполнение

Ключевое разделение в работе с агентами — режимы **Plan** и **Act/Execute**. Это не просто две фазы одной задачи, это разные режимы мышления с разными требованиями к модели, бюджету токенов, и уровню вашего контроля.

**Plan (режим планирования)**: агент анализирует задачу, исследует кодовую базу (читает файлы, изучает структуру), формирует план действий — но **не вносит изменений**. Результат этой фазы — текстовый план с последовательностью шагов, списком файлов для изменения, предполагаемым подходом к решению. Пример вывода из Plan-режима: "1. Создать middleware/rateLimiter.ts с классом RateLimiter. 2. Подключить Redis-клиент в config/redis.ts. 3. Обновить app.ts: добавить middleware после authentication. 4. Написать тесты в tests/rateLimiter.test.ts. 5. Обновить README с примером конфигурации".

**Act/Execute (режим исполнения)**: агент реализует утверждённый план — редактирует файлы, создаёт новые, запускает команды (установка зависимостей, тесты, линтер), итерирует при ошибках до выполнения критериев приёмки. В этом режиме агент автономен: не спрашивает разрешения на каждое действие, принимает решения в рамках плана.

Разделение режимов даёт три преимущества:

1. **Проверка плана до изменений**: вы видите, что агент собирается делать, и можете скорректировать до того, как написаны сотни строк кода. Это как code review архитектурного решения до начала имплементации.

2. **Оптимизация затрат**: планирование требует "умной" дорогой модели (Claude Opus, GPT-4), которая хорошо рассуждает и анализирует контекст. Исполнение часто можно делегировать более дешёвой модели (Claude Sonnet, GPT-3.5), которая следует инструкциям и пишет код по шаблону. **Enji Fleet** (учебный пример оптимизации затрат) использует эту стратегию: claude-architect (Opus) для планирования, codex-developer (дешёвая модель) для рутинной реализации.

3. **Предотвращение дрейфа**: без явного плана агент может "уйти не туда" — начать рефакторить смежный код, переписывать архитектуру, внедрять паттерны, которые вы не просили. План ограничивает scope работы.

Инструменты поддерживают разделение режимов по-разному. **Cursor** позволяет создавать custom modes (например, "Architect Mode" с инструкцией "только анализ и планирование, не изменяй код" и "Developer Mode" с полным доступом к редактированию). **OpenCode** имеет встроенные команды `opencode plan` и `opencode build`. В инструментах без нативной поддержки режимы настраиваются через промпты: "Проанализируй задачу и предложи план. НЕ вносит изменения в код" для Plan-режима, "Реализуй следующий план: [вставить план]" для Act-режима.

**Steering (управление направлением)** расширяет концепцию Plan/Act на несколько checkpoint'ов. Вместо одного большого запроса "Реализуй фичу X" используется цепочка: **research → plan → implement → verify**. Каждый checkpoint — точка проверки и корректировки.

Пример steering для задачи "Добавить систему кеширования в API":

1. **Research**: "Изучи текущую архитектуру API (routes, controllers, services). Какие endpoints самые медленные (проверь логи или профилирование)? Какие библиотеки для кеширования уже используются?"
2. **Plan**: "На основе исследования предложи план внедрения кеширования: какие endpoints кешировать, где хранить кеш (Redis, in-memory), как инвалидировать, TTL для разных типов данных."
3. **Implement**: "Реализуй план: создай cache service, добавь middleware для кеширования, обнови нужные endpoints."
4. **Verify**: "Запусти тесты. Проверь через curl, что кеш работает (первый запрос медленный, второй быстрый). Убедись, что инвалидация срабатывает при изменении данных."

На каждом этапе вы проверяете вывод агента и можете скорректировать следующий шаг. Steering особенно эффективен для задач с высокой неопределённостью, где финальное решение зависит от найденной в процессе информации.

## 4. AGENTS.md: конституция проекта

Агенты не имеют памяти между сессиями. Каждая новая сессия начинается с чистого листа: агент не помнит предыдущие решения, архитектурные договорённости, code conventions проекта. **AGENTS.md** — это файл-инструкция в корне проекта, который агент читает перед началом работы. Это **конституция**: набор правил и принципов, которые агент обязан соблюдать.

**Примечание о названиях:** В разных инструментах используются разные названия для этого файла: `AGENTS.md`, `CLAUDE.md` (синоним для Claude Code), `.cursorrules` (для Cursor). Суть одна — правила работы агента с проектом. В курсе мы используем термин **AGENTS.md** как универсальный.

Что содержит AGENTS.md:

**1. Stack (технологии проекта)**: точные версии, чтобы агент генерировал совместимый код. Не просто "используем FastAPI", а "FastAPI 0.104.1, Python 3.11, SQLAlchemy 2.0 (async), PostgreSQL 15, pytest 7.4 для тестирования, mypy strict mode для type checking".

**2. Conventions (стилевые соглашения)**: именование файлов, структура директорий, code style. Пример: "Модели БД в models/, API endpoints в routes/, бизнес-логика в services/. Имена файлов: snake_case. Классы: PascalCase. Функции: snake_case. Все async функции с суффиксом _async запрещены — используй просто async def function_name."

**3. Rules (правила разработки)**: обязательные паттерны. "Все SQL-запросы через SQLAlchemy ORM, никаких raw queries. Ошибки оборачиваются в custom exceptions (NotFoundError, ValidationError). Все endpoint handlers возвращают Pydantic models, не dict. Логирование через structlog с обязательными полями: request_id, user_id, timestamp."

**4. Forbidden (запреты)**: что агент не должен делать. "НЕ изменяй схему БД без обсуждения. НЕ удаляй существующие тесты. НЕ используй deprecated библиотеки (flask вместо FastAPI, requests вместо httpx). НЕ коммить credentials или .env файлы."

**5. Before Starting Work**: инструкции для первого шага. "Перед любой задачей: 1) прочитай AGENTS.md (этот файл), 2) прочитай docs/architecture.md, 3) найди связанные тесты и убедись, что они проходят."

Минимальный пример AGENTS.md для FastAPI-проекта:

```markdown
# Project: FastAPI E-commerce API

## Stack
- FastAPI 0.104.1, Python 3.11
- PostgreSQL 15 + SQLAlchemy 2.0 (async)
- Redis 7 для кеширования и rate limiting
- pytest + pytest-asyncio для тестов

## Structure
- models/ — SQLAlchemy models
- routes/ — API endpoints (FastAPI routers)
- services/ — бизнес-логика
- schemas/ — Pydantic schemas для API

## Conventions
- Все async, никакого sync кода в handlers
- Dependency injection для БД-сессий: db: Session = Depends(get_db)
- Type hints обязательны, mypy strict mode
- Docstrings для всех публичных функций (Google style)

## Rules
- Перед изменением БД-схемы: создать Alembic миграцию
- Каждый endpoint покрыт минимум 1 integration тестом
- Error handling: используй HTTPException с правильными status codes
- Rate limiting: все публичные endpoints через rate_limit decorator

## Forbidden
- НЕ коммить .env файлов
- НЕ использовать sync database calls
- НЕ пропускать миграции ("прямое изменение БД")
- НЕ удалять существующие тесты без обсуждения
```

**Связь с CLAUDE.md**: Claude Code (CLI-инструмент от Anthropic) по умолчанию ищет файл `CLAUDE.md` в корне проекта. Это тот же концепт, что и AGENTS.md, просто имя файла специфично для инструмента. Универсальный подход: создать `AGENTS.md` и симлинк `ln -s AGENTS.md CLAUDE.md`, чтобы работало с любым инструментом.

**Эволюция AGENTS.md**: файл не статичен. По мере работы вы обнаруживаете, что агент повторяет одни и те же ошибки — нарушает convention, использует не ту библиотеку, забывает про обязательную проверку. Каждая такая ошибка — сигнал обновить AGENTS.md. **Enji Fleet** (демонстрация эволюции знаний) использует паттерн **traces → constitution**: агенты оставляют field notes после каждой задачи (что сделано, какие проблемы, какие решения), а специализированный агент в reflect-mode консолидирует эти знания в constitution раз в неделю. Это предотвращает случайное "поломание" constitution одним агентом — обновления идут через deliberate review.
