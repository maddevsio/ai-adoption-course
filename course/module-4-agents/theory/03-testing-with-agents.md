# Тестирование в AI-assisted разработке

Без тестов AI-assisted разработка **развалится**. Агент генерирует код, который "выглядит правильно". Тесты — одна из самых эффективных детерминистических защит.

**Принцип из Enji Fleet:** прежде чем человек посмотрит на код, он должен пройти все автоматические проверки.

## Пирамида тестирования

AI радикально снижает стоимость написания тестов. То, что раньше было дорогим (E2E, интеграционные тесты), теперь создаётся за минуты. Это меняет подход: **покрытие тестами должно быть высоким, а E2E тесты — не привилегия, а необходимость**.

| Тип | Количество | Скорость | Что проверяет |
|-----|-----------|----------|---------------|
| Unit | Много (70-80%) | Миллисекунды | Отдельные функции и модули |
| Integration | Средне (15-20%) | Секунды | Взаимодействие компонентов |
| E2E | Мало (5-10%) | Минуты | Весь пользовательский сценарий |

Для AI-разработки пирамида особенно важна: **unit тесты дают быстрый feedback loop**. Агент написал код → запустил unit тесты → увидел ошибку → исправил → повторил. Если feedback loop медленный (только E2E), агент потратит токены впустую.

## Unit тесты: быстрый feedback для агента

Unit тесты проверяют отдельные функции и модули **в изоляции** от внешних зависимостей (БД, сеть, файловая система). Зависимости заменяются моками.

### Как направить агента на хорошие unit тесты

Разработчики знают как выглядят тесты. Задача — направить агента писать **качественные** тесты, а не формальные.

Ключевые инструкции для агента:
- **Явно перечислить сценарии** — без этого агент напишет 1-2 теста на happy path
- **Указать edge cases** — граничные значения, пустые строки, нули, отрицательные числа
- **Потребовать изоляцию** — каждый тест независим, использует setUp/tearDown
- **Запретить хрупкие assertions** — проверять структуру (`expect(error.code).toBe(404)`), а не точные строки

**Хороший промпт:**
```
Покрой тестами calculateDiscount в pricing.ts.
Happy path + edge cases: 0, отрицательная сумма, граничные значения 500 и 1000.
Каждый тест — один сценарий. Запусти после написания.
```

**Плохой промпт:**
```
Напиши тесты для pricing.ts
```

Без конкретных сценариев агент напишет 1-2 теста на happy path и пропустит edge cases.

## Интеграционные тесты: проверка взаимодействия

Интеграционные тесты проверяют **взаимодействие между компонентами**: код + БД, сервис + API, модуль + файловая система. Внешние зависимости — реальные (или близкие к реальным через тестовые контейнеры).

### Как направить агента на хорошие интеграционные тесты

Ключевые инструкции:
- **Указать lifecycle** — create → read → update → delete → verify deletion
- **Потребовать error cases** — 404, 400, 401 для каждого endpoint
- **Разделить от unit тестов** — build-теги (Go: `//go:build integration`), маркеры (Python: `@pytest.mark.integration`), отдельные директории
- **Указать инфраструктуру** — тестовые контейнеры, in-memory БД, или тестовый сервер

## E2E тесты: проверка всей системы

E2E (End-to-End) тесты проверяют **весь пользовательский сценарий** — от UI (или API-вызова) до базы данных и обратно. Это самый дорогой, но самый убедительный вид тестирования.

**Почему E2E критичны для agentic-разработки:** агент меняет код в нескольких местах одновременно. Unit тесты проверяют каждую часть по отдельности, но не ловят ошибки на стыках между компонентами, которые агент мог не учесть. E2E — единственный способ убедиться, что вся система работает как единое целое после изменений агента.

### Инструменты для E2E

**Frontend E2E:**
- **Playwright** (рекомендуется) — кроссбраузерные тесты, автоматические ожидания, screenshots при ошибках
- **Cypress** — альтернатива Playwright

**Backend/API E2E:**
- Скрипты с curl/httpie для проверки API lifecycle
- Docker Compose для поднятия всей инфраструктуры

### E2E в Enji Fleet: test-e2e workflow

В Enji Fleet E2E тестирование — это отдельный **workflow mode** с чёткими фазами:

```
Phase 1: Build & Deploy → поднять всю платформу
Phase 2: Create Task & Monitor → создать задачу, следить за lifecycle
Phase 3: Verify Lifecycle → проверить state machine transitions
Phase 4: UI Verification → проверить фронтенд
Phase 5: Document Results → записать в trace
```

Правила безопасности при E2E:
- **Мониторить количество контейнеров.** Spawner может создавать контейнеры в цикле
- **При crash loop — сначала остановить сервис**, потом разбираться
- **Фиксировать каждый найденный баг** в trace сразу (не накапливать)

## Стратегия тестирования для AI-проектов

### Минимальный набор (для старта)

1. **Unit тесты для бизнес-логики.** Каждая функция с нетривиальной логикой покрыта 3-5 тестами (happy path + edge cases).
2. **Интеграционные тесты для API endpoints.** Каждый endpoint: успех + основные ошибки (404, 400).
3. **Линтер + type checker** в pre-commit hook.

### Стандартный набор (для активной разработки)

1. Всё из минимального набора
2. **Coverage > 80%** для нового кода
3. **Интеграционные тесты с реальной БД** (через тестовые контейнеры)
4. **E2E тесты для критических сценариев** (авторизация, основной CRUD)
5. **Автоматический запуск** в CI/CD

### Полный набор (для production)

1. Всё из стандартного набора
2. **E2E тесты через Playwright** для UI
3. **Performance тесты** для критичных endpoints
4. **Security сканирование** (dependency audit, SAST)
5. **Contract тесты** между сервисами

### Блокирующие правила для тестов

Включите в AGENTS.md:

```markdown
## Testing Rules

**ОБЯЗАТЕЛЬНО:**
- Каждый новый endpoint покрыт минимум 1 integration тестом
- Каждая функция с бизнес-логикой покрыта unit тестами (min 3 сценария)
- Перед коммитом: все тесты проходят (0 failures)
- Coverage нового кода > 80%

**ЗАПРЕЩЕНО:**
- Код без тестов
- Пропускать falling tests ("добавлю потом")
- Удалять существующие тесты без обсуждения
- Изменять тест вместо исправления кода (если тест корректен)

**СТОП и исправь:**
- Тест падает → исправь код, пока тест не пройдёт
- Coverage ниже минимума → добавь тесты
- Линтер ругается → исправь все ошибки
```

### Типичные ошибки агентов с тестами

**Ошибка 1: Агент "исправляет" тест вместо кода**

Агент видит falling test и изменяет assertion вместо исправления бага. Это опасно — тест перестаёт проверять правильное поведение.

**Предотвращение:** "Если тест падает — исправь код, не тест. Тесты менять можно только если они содержат ошибку в самом тесте (неправильный expected value)."

**Ошибка 2: Тесты только на happy path**

Агент пишет `test_create_task_success` и считает задачу выполненной. Нет тестов на ошибки, edge cases, boundary values.

**Предотвращение:** Явно перечислите сценарии в промпте. "Покрой: success, not found (404), invalid input (400), empty input, boundary values."

**Ошибка 3: Тесты зависят друг от друга**

Тест №2 зависит от данных, созданных в тесте №1. Если тест №1 упал — весь suite падает.

**Предотвращение:** "Каждый тест должен быть независимым. Используй setUp/tearDown (или beforeEach/afterEach) для подготовки данных."

**Ошибка 4: Тесты слишком хрупкие (brittle)**

Тест проверяет точную строку ошибки: `expect(error.message).toBe("Task with ID 123 not found in database")`. Любое изменение формулировки ломает тест.

**Предотвращение:** Проверяйте структуру, не конкретные строки: `expect(error.code).toBe(404)` или `expect(error.message).toContain("not found")`.

## Автоматическое ревью как дополнительная защита

Тесты ловят поломки поведения, но не защищают от техдолга: дублирования, нарушения архитектурных конвенций, забытых TODO, утечек абстракций. Для этого нужен автоматический code review с guardrails.

**Как это работает:**
- PR создаётся агентом → автоматически запускается ревью-агент
- Ревью-агент проверяет код по чеклисту: стиль, конвенции, тесты, безопасность
- Если есть нарушения — PR блокируется до исправления

> [!NOTE]
> Тесты + автоматическое ревью = многофакторная защита. Тесты проверяют *что* код делает, ревью проверяет *как* он написан. Одно без другого оставляет слепые зоны.
