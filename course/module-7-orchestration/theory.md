# Модуль 7: Параллельные агенты и оркестрация

## От кодера к архитектору оркестра

На уровне 5 происходит фундаментальный сдвиг в роли разработчика. Кодинг не исчезает, но перестаёт быть основной деятельностью. Если раньше разработчик писал код руками (с помощью агента или без), то теперь он становится проектировщиком решений, менеджером оркестратора и контролёром качества.

**Три новые компетенции определяют эту роль:**

1. **Проектирование** — писать спецификации, которые агенты могут автономно исполнить. Чем точнее спека, тем лучше результат. Вместо того, чтобы писать код, вы пишете описание того, каким этот код должен быть. Агент превращает спецификацию в рабочее решение.

2. **Менеджмент оркестратора** — настраивать роли агентов, выбирать модели под задачи (умная модель планирует, дешёвая кодит), тюнить стратегии (когда перезапускать, когда менять агента). Вы управляете не кодом, а процессами и ресурсами.

3. **Контроль качества** — приёмка результатов, code review PR-ов от агентов, мониторинг метрик (время выполнения, количество итераций, расход токенов). Вы проверяете результат работы автономной системы, а не пишете код самостоятельно.

Аналогия из реального проекта Enji Fleet: менеджер ставит задачу → флит агентов автономно декомпозирует её на подзадачи, кодит, тестит, оформляет PR → разработчик ревьюит и мерджит. Разработчик здесь выступает как мейнтейнер флита, решатель блокеров, оптимизатор скорости работы системы.

Кодинг остаётся там, где агенты не справляются: сложная бизнес-логика без чёткой спецификации, интеграции с недокументированными API, архитектурные решения, отладка нетривиальных багов. Но объём ручного кодинга радикально снижается.

Как отмечает команда Enji Fleet: *"Разработчики становятся мейнтейнерами флита, решателями блокеров, оптимизаторами скорости флита и его ресурсов."* Это не потеря профессии — это эволюция от исполнителя к архитектору систем.

## Зачем нужна параллельность

Один агент = одна задача. Пропускная способность упирается в скорость работы агента. Если нужно реализовать фронтенд и бэкенд, один агент сделает это последовательно — сначала одно, потом другое. На это уйдёт, например, 2 часа.

Несколько агентов = несколько задач одновременно. Один агент работает над фронтендом, другой — над бэкендом, третий пишет тесты. Те же задачи выполняются за 40-50 минут, потому что всё происходит параллельно.

**Когда параллельность оправдана:**
- Фича состоит из 5+ независимых подзадач (API endpoints, UI компоненты, тесты, документация)
- Задачи не блокируют друг друга (не нужно ждать результата одной для начала другой)
- Есть бюджет на несколько параллельных сессий (токены, compute)

**Когда параллельность избыточна:**
- Маленькая задача (один баг, один endpoint) — один агент справится быстрее
- Задачи сильно связаны (нужен результат первой для начала второй)
- Первый раз делаете что-то новое — сначала проверьте на одном агенте

Честно про overhead: параллельность добавляет сложность. Нужно изолировать контексты агентов, разрешать конфликты при слиянии кода, мониторить несколько процессов. Первое время это медленнее, чем делать всё самому. Ценность проявляется в масштабе: когда нужно сделать 10 фич, а не одну, или когда система работает 24/7 и не требует вашего присутствия.

## Изоляция контекстов с git worktree

Каждый агент работает в своей сессии, со своим контекстом, в своём scope работы. Если два агента одновременно редактируют файлы в одной директории, они могут перезаписать изменения друг друга или получить конфликты merge.

Изоляция нужна для того, чтобы агенты не мешали друг другу. Один агент работает над фронтендом, другой — над бэкендом. Они не видят незакоммиченные изменения друг друга, не блокируют файлы, не создают race conditions.

**Git worktree** — простое решение: одна копия репозитория → несколько рабочих директорий → каждый агент работает в своей.

```bash
# Создать worktree для агента, работающего над задачей add-user-auth
git worktree add ../myproject-add-user-auth -b feat/add-user-auth

# Перейти в изолированную директорию
cd ../myproject-add-user-auth

# Агент работает здесь: пишет код, коммитит, создаёт PR

# После завершения работы удалить worktree
git worktree remove ../myproject-add-user-auth
```

Worktree создаёт отдельную рабочую директорию, привязанную к новой ветке. Это не клон репозитория (история общая), но файловая система изолирована. Агент работает так, как будто у него есть отдельный проект.

Правило из Enji Fleet: **каждый план = отдельный worktree**. Никогда не работайте в основной директории при параллельной разработке. Агент начинает — создаём worktree. Агент закончил (или упал) — удаляем worktree. Это дисциплина, которая предотвращает 90% проблем с конфликтами.

После завершения работы агента его ветка мерджится в main обычным образом (через PR), а worktree удаляется. Если нужно переключаться между worktrees, просто меняйте директории — каждая работает независимо.

## Ralph Loop и fail-until-done

Агент не должен останавливаться при первой ошибке. Ralph Loop — это цикл непрерывной работы агента до достижения успешного результата.

**Цикл выглядит так:**
1. **Do** — агент выполняет задачу (пишет код, создаёт файлы)
2. **Check** — запускаются проверки (тесты, линтер, билд)
3. **Fix** — если проверка упала, агент анализирует ошибку и исправляет
4. Цикл повторяется до тех пор, пока все проверки не пройдут

Критерий остановки — не "я написал код", а "все тесты зелёные, линтер молчит, билд успешен". Если тест падает, агент не останавливается и не зовёт человека — он читает ошибку, исправляет код и перезапускает проверку.

**Пример: добавить API endpoint для получения списка пользователей**

Итерация 1:
```
DO: Агент пишет endpoint GET /users
CHECK: pytest → test_users_list FAILED (forgot to filter deleted users)
FIX: Агент добавляет фильтр .filter(deleted_at=None)
```

Итерация 2:
```
DO: Код обновлён
CHECK: pytest → все тесты зелёные, но mypy → Missing return type annotation
FIX: Агент добавляет -> List[UserSchema]
```

Итерация 3:
```
DO: Код обновлён
CHECK: pytest ✓, mypy ✓, ruff ✓, go build ✓
DONE: Все проверки пройдены → агент коммитит и создаёт PR
```

**Fail-until-done** (подход из Enji Fleet) означает, что агент маслает, пока не сделает. Нет понятия "я попробовал и не вышло". Есть понятие "я буду пробовать, пока не получится, или пока не упрусь в hard limit" (например, 50 итераций или 3 часа работы).

Ссылки для изучения:
- https://ghuntley.com/ralph/ — оригинальная концепция Ralph Loop
- https://dev.to/alexandergekov/2026-the-year-of-the-ralph-loop-agent-1gkj — почему Ralph Loop стал стандартом

Ralph Loop работает, когда критерии успеха формализованы и автоматически проверяемы. Если критерий "код должен выглядеть красиво" — агент не поймёт, когда остановиться. Если критерий "все тесты пройдены, coverage > 80%, линтер без ошибок" — агент знает, что делать.

## Ролевая модель агентов

Не стоит использовать один универсальный агент на все задачи. Опыт Enji Fleet показывает: специализированные роли работают эффективнее.

**Четыре ключевые роли:**

1. **Архитектор** — анализирует требования, проектирует архитектуру системы, выбирает технологический стек.
   - Модель: умная и дорогая (Claude Opus 4.6 или GPT-5)
   - Задачи: проектирование на уровне системы, ADR (Architecture Decision Records), выбор паттернов
   - Когда использовать: начало проекта, новая крупная фича, рефакторинг архитектуры

2. **Планировщик** — декомпозирует задачу на атомарные подзадачи с зависимостями.
   - Модель: средняя по цене и качеству (Claude Sonnet 4.5)
   - Задачи: создание плана работ, определение порядка выполнения, формирование критериев приёмки
   - Когда использовать: после архитектурного проектирования, перед началом разработки

3. **Разработчик** — реализует конкретную атомарную задачу, делает self-check (линтер, тесты).
   - Модель: дешёвая и быстрая (Claude Haiku, Codex Mini, Gemini Flash)
   - Задачи: написание кода по спецификации, создание тестов, запуск проверок
   - Когда использовать: основная масса работы — имплементация задач из плана

4. **QA / Ревьюер** — тестирует результат, проверяет соответствие требованиям, формирует баг-репорт.
   - Модель: средняя (Claude Sonnet)
   - Задачи: интеграционное тестирование, проверка edge cases, формирование отчёта о проблемах
   - Когда использовать: после завершения разработки, перед мерджем в main

**Принцип: разные модели для разных ролей.** Не тратить Opus ($15 за 1M input tokens) на написание boilerplate кода. Не ставить Haiku ($0.80 за 1M input tokens) на архитектурное проектирование. Планировщик на Sonnet ($3 за 1M input tokens) — золотая середина для декомпозиции задач.

**Пример конфигурации из Enji Fleet (agent-profiles.yaml):**

```yaml
claude-developer:
  roles: [developer, reviewer, tester]
  model: claude-sonnet-4-5-20250929
  max_turns: 100
  priority: normal

claude-architect:
  roles: [planner, reviewer, evaluator]
  model: claude-sonnet-4-5-20250929
  max_turns: 50
  priority: high

codex-developer:
  roles: [developer, tester]
  model: codex-mini
  priority: low
```

Architect с `priority: high` означает, что если несколько агентов конкурируют за ресурсы, архитектор получает приоритет. Codex Developer с `priority: low` используется для дешёвых и некритичных задач.

**Agents-hot-swap** — если агент зациклился, упёрся в rate limit или выдал N неудачных результатов подряд, оркестратор заменяет его другим агентом с той же ролью. Например, Claude Developer не справился с задачей за 20 итераций → оркестратор заменяет его на Gemini Developer или эскалирует задачу на более умную модель (Codex Mini → Claude Sonnet).

Задачи атомарные, поэтому замена безболезненна: новый агент читает задачу, контекст проекта (constitution.md), смотрит на текущий код и продолжает работу. Все роли общаются через координатора, не напрямую. Координатор принимает решение о замене агента.

## Паттерны оркестрации

### Паттерн 1: Генератор + Ревьюер

Простейший паттерн для повышения качества кода. Один агент пишет код, другой проверяет.

**Как работает:**
1. Агент-генератор получает задачу "добавить endpoint /api/products"
2. Генератор пишет код и отправляет на проверку
3. Агент-ревьюер проверяет код по критериям: тесты написаны? документация есть? нет SQL-инъекций? соответствие code style?
4. Если ревьюер находит проблемы, он отправляет результат обратно генератору с конкретными замечаниями
5. Генератор исправляет и отправляет снова
6. Цикл повторяется до одобрения ревьюера

**Когда использовать:**
- Критичный код (безопасность, финансы, медицина)
- Работа с legacy кодом, где нужна extra осторожность
- Задачи, где один агент часто ошибается (например, работа с незнакомым фреймворком)

**Плюсы:** значительно повышает качество кода, отлавливает ошибки, которые пропускает генератор.

**Минусы:** в 2 раза дороже по токенам, дольше по времени. Избыточен для простых задач типа "добавить поле в модель".

### Паттерн 2: Декомпозиция

Разбить фичу на независимые подзадачи и раздать их разным агентам одновременно.

**Пример: фича "регистрация пользователя"**
- Агент 1: API endpoint `POST /api/auth/register` + валидация (30 минут)
- Агент 2: UI форма регистрации на React (30 минут)
- Агент 3: E2E тесты для флоу регистрации (30 минут)

Все три агента работают параллельно. Вместо 90 минут последовательной работы — 30-40 минут с учётом времени на слияние результатов.

**Когда использовать:**
- Фича естественно делится на независимые части (backend, frontend, tests)
- Подзадачи слабо связаны (не требуют результата друг друга)
- Есть бюджет на несколько параллельных сессий

**Плюсы:** значительное ускорение при многокомпонентных задачах.

**Минусы:** нужна координация при слиянии, возможны конфликты если агенты случайно редактируют общие файлы (например, shared types).

### Паттерн 3: Иерархия (RPI→R из Enji Fleet)

Координатор управляет цепочкой: **Research → Plan → Implement → Review**. Координатор не пишет код, а формирует задачи с чёткими критериями приёмки для каждого этапа.

**Этапы:**

1. **Research** — агент изучает требования, анализирует существующий код, определяет границы системы.
   - Вопросы: какие API нужны? с чем интегрироваться? какие edge cases учесть?
   - Артефакт: документ с результатами исследования

2. **Plan** — агент-планировщик получает результаты research и создаёт план задач.
   - Иерархия: Roadmap → Phase → Task → Atomic Task
   - Агент не имеет права писать код, пока не спустится до уровня Atomic Task
   - Артефакт: список атомарных задач с зависимостями и критериями приёмки

3. **Implement** — агенты-разработчики берут атомарные задачи и реализуют их.
   - Каждая задача выполняется в отдельном worktree
   - Self-check: линтер, тесты, билд
   - Артефакт: PR с кодом и тестами

4. **Review** — агент-QA проверяет результат.
   - Интеграционное тестирование
   - Проверка соответствия требованиям из Research
   - Если валидатор не принял — задача возвращается в Implement с конкретными замечаниями

**Координатор** отслеживает состояние всей цепочки: какие задачи в работе, какие завершены, какие заблокированы. Если агент долго не прогрессирует, координатор может заменить его (hot-swap) или перепланировать задачу.

**Когда использовать:**
- Крупные фичи с неочевидными требованиями
- Проекты, где важна трассируемость (каждое решение задокументировано)
- Работа с незнакомым доменом, где нужен предварительный research

**Плюсы:** высокое качество планирования, минимум переделок, чёткая история принятия решений.

**Минусы:** overhead на координацию, медленнее для простых задач. Избыточен для "добавить кнопку на форму".

## Runbook и "Библия" оркестратора

**Runbook** — формализованный план работы для нескольких агентов. Это не просто список задач, а инструкция с ролями, порядком выполнения, критериями приёмки и процедурой слияния результатов.

**Структура runbook:**
- **Цель** — что делаем и зачем
- **Подзадачи** — список атомарных задач
- **Распределение** — какая задача какому агенту (роль + профиль)
- **Порядок** — какие задачи можно делать параллельно, какие последовательно
- **Критерии приёмки** — как понять, что задача сделана правильно
- **Процедура слияния** — как соединить результаты разных агентов

**Пример runbook для фичи "Export пользователей в CSV":**

```markdown
Цель: Добавить возможность экспорта списка пользователей в CSV через API и UI

Задачи:
1. [Backend] API endpoint GET /api/users/export → возвращает CSV (агент: codex-developer)
   - Критерий: endpoint работает, все поля экспортируются, тесты покрывают edge cases

2. [Frontend] Кнопка Export в таблице пользователей (агент: claude-developer)
   - Критерий: клик → скачивается CSV, показывается loader, обработаны ошибки

3. [Tests] E2E тест полного флоу экспорта (агент: claude-developer)
   - Критерий: тест проходит, покрывает позитивный и негативный сценарии

Порядок: задачи 1 и 2 параллельно, задача 3 после завершения обеих.

Слияние: backend мерджится первым, затем frontend (зависит от API), затем тесты.
```

**Библия** (концепция из Enji Fleet) — это верхнеуровневый ценностный документ, который определяет "кто ты, что ты, для чего ты, кому и как помогаешь". От библии выкристаллизовывается вся спека для флита.

Разные проекты = разные библии. Флит для HR-ботов работает иначе, чем флит для веб-приложений. Библия фиксирует:
- Целевые пользователи (разработчики проекта? сотрудники компании?)
- Типы задач (фичи в существующем проекте? создание новых приложений с нуля?)
- Стандарты качества (минимальный test coverage, обязательные проверки)
- Процессы деплоя (автоматический в staging? ручной в production?)
- Тон коммуникации (коммиты на русском? PR descriptions детальные?)

Библия оживляет флит на конкретный поток ценности. Без библии флит функционален, но не имеет контекста. С библией флит знает, как работать именно с вашим проектом.

## Мониторинг, конфликты и lessons learned

### Мониторинг агентов

Heartbeat от агентов — каждый агент периодически (раз в 5-10 минут) сообщает оркестратору: "я жив, работаю над задачей X, прогресс Y%". Если агент долго не отвечает (20-30 минут тишины), оркестратор считает его упавшим и перезапускает задачу на другом агенте.

**Логи действий** — что агент делал:
- 10:15 — прочитал constitution.md
- 10:17 — создал worktree для feat/add-export
- 10:20 — написал endpoint /api/users/export
- 10:22 — запустил тесты → 1 failed
- 10:25 — исправил баг в фильтрации
- 10:27 — тесты passed, линтер passed
- 10:30 — создал PR #234

Логи позволяют отследить, где агент застрял, сколько итераций потребовалось, на каком шаге возникла проблема.

**Метрики:**
- Время на задачу (median, p95) — сколько в среднем агент тратит на атомарную задачу
- Количество итераций до успеха — сколько раз агент прогонял цикл Do→Check→Fix
- Расход токенов — сколько стоила задача в деньгах
- Процент успешных завершений — сколько задач агент довёл до PR без ручного вмешательства

Если метрики показывают, что агент с профилем X плохо справляется с задачами типа Y, это сигнал для оптимизации: сменить модель, улучшить промпт, переназначить задачи другому агенту.

### Конфликты при слиянии

Два агента изменили один файл — классический merge conflict. Как разрешить:

1. **Ручное ревью** (самый надёжный способ) — человек смотрит на оба изменения и решает, как их объединить. Используется для критичного кода.

2. **Агент-арбитр** — третий агент читает оба варианта кода и предлагает решение. Работает для простых конфликтов (например, два агента добавили разные функции в один файл).

3. **Повторный запуск одного из агентов** — откатываем изменения одного агента и перезапускаем его задачу с учётом изменений другого. Используется, если один агент явно имеет приоритет.

Лучшая стратегия — предотвращение конфликтов на этапе планирования. Если два агента должны работать с одним файлом, либо делайте это последовательно, либо разделите файл на модули, которые можно редактировать независимо.

### Lessons learned: эволюция знаний

Агент после сложной задачи фиксирует, что пошло не так и как это было решено. Эти знания доступны другим агентам и улучшают работу оркестратора со временем.

**Три типа памяти (из Enji Fleet):**

1. **Состояние работы** (git-based) — что сделано, что осталось. Решается через git: коммиты, PR, issue tracking. Граф зависимостей между задачами.

2. **Контекст проекта** (артефакты) — архитектура, технический стек, принятые решения. Хранится в `docs/constitution.md`, `docs/decision-log.md`. Агент читает это в начале каждой сессии.

3. **Знания по самоулучшению** (lessons → skills) — переносимая память между проектами. Агент решил сложный баг с async/await в Python → записал lesson "При работе с asyncio всегда проверяй event loop policy". Эти lessons консолидируются в skills, которые становятся доступны всем агентам флота.

**Пример lesson:**

```markdown
Задача: Добавить WebSocket endpoint для real-time уведомлений
Проблема: Тесты падали с ошибкой "RuntimeError: Event loop is closed"
Решение: В pytest.ini добавить asyncio_mode = auto и использовать pytest-asyncio

Lesson для constitution:
При тестировании asyncio кода в pytest обязательно:
1. Установить pytest-asyncio
2. Добавить asyncio_mode = auto в pytest.ini
3. Маркировать async тесты декоратором @pytest.mark.asyncio
```

Этот lesson попадает в constitution, и следующий агент, работающий с asyncio, не совершит ту же ошибку.

Со временем оркестратор накапливает базу знаний: какие паттерны работают, какие модели лучше для каких задач, какие ошибки типичны и как их избегать. Система становится умнее не за счёт обновления моделей, а за счёт накопления контекстуальных знаний.

## Дополнительные возможности для параллельной разработки

### Headless-режим Claude Code

Claude Code может работать без UI в headless-режиме:

```bash
# Запуск агента с промптом из файла
claude -p prompt.md

# Запуск на удалённом сервере (EC2, VPS, Docker)
ssh production-server "claude -p 'fix authentication bug in users service'"
```

Headless-режим позволяет запускать агентов в облаке, на CI/CD серверах, внутри Docker-контейнеров. Масштабирование за пределы одной машины: вместо 3 агентов на вашем ноутбуке — 20 агентов на выделенных серверах.

**GitHub Actions:**
```yaml
- name: Run Claude Code Agent
  uses: anthropics/claude-code-action@v1
  with:
    prompt-file: .github/prompts/fix-failing-tests.md
    anthropic-api-key: ${{ secrets.ANTHROPIC_API_KEY }}
```

**GitLab CI/CD:**
```yaml
agent-task:
  image: anthropics/claude-code:latest
  script:
    - claude -p .gitlab/prompts/add-feature.md
```

Агенты в CI интегрируются в пайплайн: код закоммитен → CI запускает агента для генерации тестов → агент создаёт PR с тестами → человек ревьюит.

### Долговременные auth-токены

Для headless-автоматизации нужны токены, которые не истекают после logout.

**Для API-биллинга:**
```bash
export ANTHROPIC_API_KEY=sk-ant-api03-...
```

Токен API получается в console.anthropic.com. Биллится по usage (pay-as-you-go). Подходит для production систем с предсказуемым объёмом работы.

**Для подписчиков Claude Max (OAuth токен на 1 год):**
```bash
# Генерация долговременного токена
claude setup-token

# Использование в headless-режиме
export CLAUDE_CODE_OAUTH_TOKEN=eyJhbGci...
```

OAuth токен живёт 1 год, не требует ручной перегенерации. Подходит для экспериментов и небольших команд (до 5 агентов).

**Альтернативные провайдеры:**
- **Amazon Bedrock:** `CLAUDE_CODE_USE_BEDROCK=1` — Claude через AWS с корпоративным биллингом
- **Google Vertex AI:** интеграция через GCP, подходит для компаний с инфраструктурой на Google Cloud
- **Azure Foundry:** Claude через Microsoft Azure для enterprise-клиентов

Выбор провайдера зависит от существующей инфраструктуры и compliance требований. Если компания работает в AWS, Bedrock проще интегрировать, чем прямой API.

### Claude Agent SDK

Официальный SDK для построения кастомных оркестраторов:

**Python:**
```bash
pip install claude-agent-sdk
```

```python
from claude_agent_sdk import AgentSession, Tool

# Создать сессию агента
session = AgentSession(
    model="claude-sonnet-4-5",
    system_prompt="You are a backend developer"
)

# Запустить задачу
result = session.run(
    prompt="Add rate limiting to /api/users endpoint",
    tools=[Tool.Bash, Tool.Read, Tool.Edit, Tool.Write]
)

# Результат: код написан, тесты пройдены, PR создан
print(result.pr_url)
```

**TypeScript:**
```bash
npm install @anthropic-ai/claude-agent-sdk
```

```typescript
import { AgentSession } from '@anthropic-ai/claude-agent-sdk';

const session = new AgentSession({
  model: 'claude-sonnet-4-5',
  systemPrompt: 'You are a frontend developer'
});

const result = await session.run({
  prompt: 'Add dark mode toggle to settings page',
  tools: ['Bash', 'Read', 'Edit', 'Write']
});
```

SDK позволяет:
- Создавать программные субагенты (не через CLI, а через код)
- Добавлять кастомные хуки (перед запуском, после завершения, при ошибке)
- Интегрировать MCP-серверы для доступа к внешним системам
- Управлять несколькими сессиями из одного скрипта

**Пример: бот, который берёт задачи из Jira**

```python
from claude_agent_sdk import AgentSession
from jira import JIRA

jira = JIRA('https://company.atlassian.net', basic_auth=('user', 'token'))

# Получить задачи из бэклога
issues = jira.search_issues('project=BACKEND AND status="To Do"')

for issue in issues:
    # Создать агента для задачи
    session = AgentSession(model="claude-sonnet-4-5")

    # Запустить реализацию
    result = session.run(
        prompt=f"Task: {issue.summary}\n\nDescription: {issue.description}",
        working_dir=f"/tmp/worktree-{issue.key}"
    )

    # Обновить статус в Jira
    if result.success:
        jira.transition_issue(issue, 'In Review')
        issue.update(fields={'comment': f'PR created: {result.pr_url}'})
```

SDK превращает Claude Code из CLI-инструмента в программируемую платформу для автоматизации.

### Agent Teams (experimental)

Экспериментальная функция для координации нескольких агентов:

```bash
export CLAUDE_CODE_EXPERIMENTAL_AGENT_TEAMS=1
claude teams start --agents 3
```

**Возможности:**
- **Shared task list** — все агенты видят общую очередь задач и берут следующую свободную
- **Inter-agent messaging** — агенты могут запрашивать информацию друг у друга ("Agent 1 спрашивает Agent 2: какой API endpoint ты создал?")
- **Plan approval mode** — агенты предлагают план работ, человек одобряет, агенты исполняют автономно

**Пример из Anthropic:**
Команда запустила 16 параллельных агентов для работы над Rust-компилятором проекта C. За ~2000 сессий агенты написали и отрефакторили около 100K строк кода. Большинство PR-ов были приняты после minimal review.

Agent Teams пока в experimental статусе. Проблемы: координация требует значительного overhead, межагентное общение может создавать циклические зависимости, стоимость 16 параллельных Sonnet сессий высокая. Но технология показывает, что возможно.

### OpenClaw: платформа автономных агентов

**OpenClaw** (https://github.com/openclaw/openclaw, 188K stars) — open-source платформа автономных агентов от Питера Штайнбергера.

**Ключевые возможности:**
- **Multi-agent routing** — разные модели на разные задачи (Claude для кода, GPT-4 для анализа текста, Gemini для поиска)
- **Интеграция с Claude Code через MCP** — OpenClaw вызывает Claude Code как один из инструментов
- **Экосистема оркестраторов:**
  - **Claworc** — управление инстансами агентов, масштабирование на сотни worker'ов
  - **Antfarm** — team-of-agents паттерн, агенты совместно решают задачу

OpenClaw **не для кода напрямую**, а для координации: работа со Slack, Jira, email, браузер + code agents. Например:
1. Пользователь пишет в Slack: "fix bug PROJ-123"
2. OpenClaw читает сообщение, берёт задачу из Jira
3. OpenClaw запускает Claude Code для исправления бага
4. Результат (PR) отправляется обратно в Slack

OpenClaw — слой координации над разными AI-инструментами. Если Claude Code — это "агент умеет писать код", то OpenClaw — это "платформа умеет управлять агентами, которые пишут код, общаются в Slack и обновляют таски".

Для использования OpenClaw нужна инфраструктура: сервер для запуска платформы, интеграции с корпоративными системами, настройка routing между моделями. Это решение для компаний, которые хотят построить полноценную автономную систему разработки, а не для индивидуальных разработчиков.

## Честно про сложности

Параллельность добавляет overhead. Вот о чём нужно знать:

**1. Первое время медленнее, чем делать самому**

Первые несколько недель работы с оркестратором вы будете тратить больше времени на настройку, отладку, разрешение конфликтов, чем если бы писали код вручную. Агенты будут ошибаться, зацикливаться, создавать неоптимальный код. Вы потратите часы на написание runbook, настройку профилей агентов, отладку worktree workflow.

Это нормально. Ценность не в первой задаче, а в масштабе. На десятой задаче процесс начнёт работать плавно. На сотой — вы уже не представляете, как делали это вручную.

**2. Нужна инфраструктура**

Git worktrees, headless-режим, credential management, мониторинг агентов — всё это требует первоначальной настройки. Если вы работаете один, настройка займёт 2-3 дня. Если команда из 5 человек — неделю. Если компания с compliance требованиями — месяц.

Плюс: инфраструктура настраивается один раз. Дальше она работает автоматически.

**3. Стоимость**

Один агент в headless-режиме, работающий 8 часов в день на Claude Sonnet, обходится примерно в $50-80/месяц (зависит от объёма кода и количества итераций). Три параллельных агента = $150-240/месяц.

Для сравнения: зарплата разработчика $5000-10000/месяц. Если агенты закрывают хотя бы 30% рутинных задач, ROI положительный. Но начальные инвестиции в $200-500/месяц на эксперименты нужно заложить в бюджет.

**4. Когда НЕ нужна параллельность**

- Маленький проект (1-2 человека, 1-2 месяца разработки) — overhead не окупится
- Исследовательская задача без чётких критериев ("попробуй разные подходы и посмотри что получится")
- Legacy код с zero tests и zero документацией — агенты не смогут понять контекст
- Задачи с высоким уровнем креативности и субъективной оценки ("сделай красиво")

Параллельность хороша для повторяющихся, формализованных, автоматически проверяемых задач. Если критерий успеха — "тесты пройдены, линтер молчит, PR создан", агенты справятся. Если критерий — "код должен чувствоваться правильно", нужен человек.

**5. Ответственность остаётся на вас**

Агент создал PR, вы его смерджили, код попал в production и сломал систему. Ответственность несёте вы, а не агент. Поэтому:
- Всегда ревьюйте PR-ы от агентов (хотя бы бегло)
- Обязательные автоматические проверки (CI, тесты, security scans)
- Staging environment для проверки перед production
- Rollback plan на случай проблем

Агенты — это инструменты, которые многократно увеличивают вашу продуктивность. Но финальное решение о merge, deploy, release принимаете вы.

---

**Итог модуля:** Параллельность и оркестрация — это переход от "я пишу код" к "я проектирую систему, которая пишет код". Первое время это сложнее и медленнее. Но когда система настроена, вы получаете производительность команды из 5-10 человек, работая в одиночку или с небольшой командой. Ваша роль меняется от кодера к архитектору оркестра — и это нормальная эволюция профессии в эпоху AI-агентов.
