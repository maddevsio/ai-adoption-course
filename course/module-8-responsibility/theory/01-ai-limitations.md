[← Оглавление](../../../README.md)

# Модуль 8: Ответственное использование ИИ

## 1. Ограничения ИИ

ИИ — мощный инструмент, но он не всемогущ. Эти ограничения не делают ИИ бесполезным, но требуют осознанного подхода.

#### **Галлюцинации**
Модель может уверенно выдать несуществующую информацию. Ответы LLM убедительны, **выглядят правдоподобно**. 

Типичные примеры: предложить использовать библиотеку `fast-json-validator` для Node.js с детальным описанием API и ссылкой на npm, хотя такой библиотеки не существует.

Причина галлюцинаций: модель обучена рассчитывать вероятности, а не проверять факты. Если в обучающих данных часто встречается фраза "используйте библиотеку X для задачи Y", модель воспроизведёт её. 

Решение: перед имплементации нужно валидировать план через других агентов, проверять особо важные решения самостоятельно.

**Контекстное окно** ограничено, даже у самых современных моделей. Модель не всегда может поместить все нужные данные в свою память. Она "забывает" начало длинной сессии и начинает бредить.

Решение: систематически сохранять и обслуживать артефакты (см. Модуль 5)

#### **Sycophancy** 
Склонность соглашаться с пользователем, даже если он неправ. Это побочный эффект обучения с подкреплением (RLHF): модель оптимизирована быть "полезной и гармоничной", что означает избегание конфликта. Если вы скажете "этот код правильный, да?", модель скорее подтвердит, даже если видит явные ошибки. Более того, если вы настаиваете на неправильном подходе, модель может "сдаться" и реализовать его, добавив оправдания.

Пример: вы предлагаете использовать `eval()` в JavaScript для парсинга JSON из ненадёжного источника. Модель может написать: "Хорошо, используем eval(). Убедитесь, что данные доверенные."

#### **Предвзятость данных**
Модели обучены на данных из интернета, который полон некачественных данных: устаревший код, субъективные мнения. Модель не знает, какие практики актуальны для вас, если это не было явно в промпте и документации.

Предвзятость проявляется и в выборе технологий: модель может чаще предлагать мейнстримные решения, которые не всегда подходят для задачи. 

Решение: явно указывайте требования, проверяйте актуальность предложенных решений.

#### **Garbage in — garbage out** 
Качество результата прямо зависит от качества вводных данных. Нечёткое ТЗ приведёт к нечёткому коду.

Пример из практики: "добавь валидацию" → модель добавит проверку `if (!data) return error`, которая бесполезна. 

Решение: управляйте контекстом своего проекта, документируйте свои предпочтения - это поможет модели понимать ваши требования лучше. В особых случаях готовьте промпты вместе с ИИ, чтобы описать задачу в удобном для агента виде
---

[← Чеклист готовности](../../module-7-orchestration/practice/06-checklist.md) | [Оглавление](../../../README.md) | [2. Безопасность →](02-security.md)
