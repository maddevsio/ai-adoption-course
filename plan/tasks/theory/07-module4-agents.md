# Задача 07: Модуль 4 — Работа с AI-агентом (теория)

## Цель

Написать текст теоретической части Модуля 4. Переход от "использую ИИ" к "работаю с агентом". Включить алгоритм выбора между human-in-the-loop и agentic mass generation.

## Что написать

Текст на ~1000 слов.

1. **Агент vs чат** (2-3 абзаца):
   - Чат: ты спрашиваешь — он отвечает. Один вопрос — один ответ. Нет доступа к файлам.
   - Агент: ты ставишь задачу — он читает код, пишет файлы, запускает команды, итерирует.
   - Цикл агента: plan → act → observe → adjust.
   - Аналогия: чат = справочник, агент = джуниор-разработчик, которому ты ставишь задачу.

2. **Как ставить задачу агенту** (3-4 абзаца):
   - Декомпозиция: разбей большую задачу на подзадачи.
   - Контекст: укажи что уже есть, где лежит, какие конвенции.
   - Критерии приёмки: что значит "сделано" (тесты проходят, линтер чистый, формат X).
   - Используй агента-планировщика: описываешь проблему → агент декомпозирует на подзадачи → ты ревьюишь план → агент реализует.
   - Сразу фреймить агента на тестирование: линтер, тесты, критерии приёмки — часть задания, а не отдельный этап.

3. **Режимы работы: планирование и исполнение** (2-3 абзаца):
   - Ключевое разделение — **Plan** и **Act/Execute**:
     - Plan: агент анализирует задачу, исследует codebase, формирует план действий — без внесения изменений
     - Act: агент реализует план — редактирует файлы, запускает команды, итерирует до результата
   - Разделение режимов даёт: проверить план до начала изменений, использовать разные модели для разных фаз (дорогая модель для планирования, дешёвая для исполнения), избежать ситуации "агент уходит не туда" на сотни строк кода
   - Инструменты поддерживают нативно: Kilo Code (Architect/Code modes), OpenCode (Plan/Build), Cursor (custom modes). В других — настраивается через промпты и sub-agents
   - **Steering агентов**: вместо одного большого запроса — цепочка checkpoints: research → plan → implement → verify. Каждый этап можно проверить и скорректировать до того, как агент зайдёт далеко в неверном направлении

4. **Настройка правил: AGENTS.md** (2-3 абзаца):
   - Что это: файл-инструкция для агента в корне проекта (AGENTS.md, .cursorrules)
   - Что писать: стек, конвенции, структура проекта, правила, запреты
   - Пример минимального AGENTS.md (5-10 строк)
   - Как это связано с CLAUDE.md (альтернативное имя для Claude Code)

5. **Human-in-the-loop vs Agentic mass generation** (3-4 абзаца):
   - Два режима работы с агентом:
     - **Human-in-the-loop**: ты контролируешь каждый шаг. Агент предлагает → ты подтверждаешь → агент делает. Подходит для: критичный код, unfamiliar territory, security-sensitive.
     - **Agentic mass generation**: агент работает автономно, ты ревьюишь результат. Подходит для: рутинные задачи, boilerplate, тесты, документация, примитивные CRUD.
   - Алгоритм выбора:
     - Задача критична для бизнеса? → human-in-the-loop
     - Код будет в production? → human-in-the-loop (минимум ревью после)
     - Задача рутинная и паттерн известен? → agentic
     - Есть хорошие тесты для проверки? → можно agentic
     - Работа с чувствительными данными? → human-in-the-loop
   - Оба подхода имеют ограничения: human-in-the-loop медленный, agentic может генерировать некачественный код
   - На практике: начинать с human-in-the-loop, переходить к agentic по мере доверия и настройки правил

6. **Повышение качества через инструменты самопроверки** (1-2 абзаца):
   - LLM генерирует код, который "выглядит правильно", но может содержать subtle bugs, security issues, нарушать conventions проекта
   - Решение: интегрировать в workflow агента детерминистические инструменты — линтеры, type checkers, тесты, security scanners
   - Практически: через hooks (автоматический запуск после изменений) или явные инструкции в CLAUDE.md: "После каждого изменения запусти `npm run lint && npm test`"
   - TDD-подход особенно эффективен: сначала тесты, потом реализация — агент итерирует пока тесты не зелёные

7. **Тизер следующих модулей** (1 абзац):
   - Агент с AGENTS.md — хорошо, но можно лучше: спецификации (Модуль 5), MCP (Модуль 6), параллельная работа (Модуль 7).

## Тон и стиль

- Конкретный: каждое утверждение подкреплено примером
- Без страхов: "агент может ошибиться, поэтому проверяем"
- Алгоритм выбора human-in-the-loop vs agentic — практичный, без догматизма

## Формат результата

MD-файл `course/module-4-agents/theory.md`

## Критерии приёмки

- Разница агент/чат объяснена понятно
- AGENTS.md (не CLAUDE.md) как основной артефакт
- Алгоритм выбора human-in-the-loop vs agentic — с конкретными критериями
- Plan/Act разделение режимов с примерами инструментов
- Steering: цепочка checkpoints (research → plan → implement → verify)
- Инструменты самопроверки: hooks, TDD-подход с агентами
- Пример использования агента-планировщика для декомпозиции
- Нет терминов без объяснения

## Зависимости

- Задача 03 (фиксация стека)

## Входные данные

- `sources/Контент-план по курсу ИИ.pdf` — Модуль 3: агенты, правила, режимы, надзор
- `sources/Портрет ИИ зрелости.md` — уровень 3 (Драйвер агентов)
- `sources/старый документ: уровни AI usage maturity.pdf` — Уровень 3
- `sources/enji-fleet-analysis.md` — практики 1, 2, 11 (конституция, workflows, автономный промпт)
- `sources/AI-Assisted Development Adoption.pdf` — секции 4-6: Plan/Act режимы, правила/настройки, инструменты самопроверки

## Материалы для агента-исполнителя

- https://www.humanlayer.dev/blog/writing-a-good-claude-md — best practices для CLAUDE.md
- https://agents.md/ — универсальный формат AGENTS.md
- https://code.claude.com/docs/en/best-practices — официальная документация Claude Code
- https://factory.ai/news/using-linters-to-direct-agents — как автоматика может "бить агенту по рукам"
- https://agentic-coding.github.io/ — манифест агентного кодинга
- https://www.humanlayer.dev/blog/writing-a-good-claude-md — "Never send an LLM to do a linter's job"

## Примеры из Enji Fleet (обязательно использовать)

Репозиторий: `/home/kb/Documents/workspace/mad_devs/enji-fleet`

### Для секции "AGENTS.md"
Показать реальный AGENTS.md из Fleet (`AGENTS.md`). Обратить внимание:
- Чёткая приоритизация принципов (SoC > DRY > KISS > SOLID)
- Секция "Before Starting Work" -- агент обязан прочитать constitution перед работой
- TDD approach: "Machine acceptance precedes human acceptance"
- Секция Bash Guidelines -- конкретные правила для CLI-команд

### Для секции "Режимы работы"
Четыре workflow-файла в `.agent/workflows/`:
- **dev-mode**: "Research first, fix second" + субагенты + инкрементальный trace
- **doc-mode**: только документация, запрет на код
- **reflect-mode**: агент-аудитор, который НЕ пишет код, а консолидирует знания
- **push**: commit + PR + Telegram-пост (полный pipeline)

### Для секции "Human-in-the-loop vs Agentic"
Из `docs/prompts/code-implementation-prompt.md`:
- Агент действует автономно: "Не спрашивай разрешения на создание файлов, установку инструментов"
- Но есть блокирующие правила: "СТОП если тест падает"
- Спрашивает ТОЛЬКО если: требования противоречивы, невозможно продолжить, критическая ошибка
